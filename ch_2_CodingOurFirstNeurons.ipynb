{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "## Coding Our First Neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Single Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "inputs = [1, 2, 3]\n",
    "# inputs associated weights\n",
    "weights = [0.2, 0.8, -0.5] \n",
    "# bias - need one for each neuron (tunable parameter)\n",
    "bias = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 2.3\n"
     ]
    }
   ],
   "source": [
    "output = (inputs[0] * weights[0] +\n",
    "          inputs[1] * weights[1] +\n",
    "          inputs[2] * weights[2] + bias)\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 4.8\n"
     ]
    }
   ],
   "source": [
    "# We have 4 inputs now\n",
    "\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "# need to add the associated weight for this 4th input\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2 # stays the same\n",
    "output = (inputs[0] * weights[0] +\n",
    "          inputs[1] * weights[1] +\n",
    "          inputs[2] * weights[2] +\n",
    "          inputs[3] * weights[3] + bias)\n",
    "print(f\"Output: {output}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Layer of Neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each neuron in a layer (layer 3) takes the exact same inputs\n",
    "- inputs can either be from training data or from the previous layer\n",
    "![image.png](references/layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "# we will use 1st neuron and add 2 more neurons for layer\n",
    "\n",
    "# each neuron gets the same inputs\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "# each neuron has its own weights\n",
    "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "\n",
    "# each neuron has its own bias\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "outputs = [\n",
    "    # Neuron 1:\n",
    "    inputs[0] * weights1[0] +\n",
    "    inputs[1] * weights1[1] +\n",
    "    inputs[2] * weights1[2] +\n",
    "    inputs[3] * weights1[3] + bias1,\n",
    "    # Neuron 2:\n",
    "    inputs[0] * weights2[0] +\n",
    "    inputs[1] * weights2[1] +\n",
    "    inputs[2] * weights2[2] + \n",
    "    inputs[3] * weights2[3] + bias2,\n",
    "    # Neuron 3:\n",
    "    inputs[0] * weights3[0] + \n",
    "    inputs[1] * weights3[1] + \n",
    "    inputs[2] * weights3[2] + \n",
    "    inputs[3] * weights3[3] + bias3]\n",
    "\n",
    "print(f\"Output: {outputs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each neuron is connected to the same inputs\n",
    "- only difference is the weights and biasees that each neuron applies to the input\n",
    "- this is a fully connected neural network: every neuron in the current layer has connections to every neuron from the previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Outputs: [4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "# Using Loops to Scale Layers and inputs sizes\n",
    "\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "# change weights to one list\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "# change biases to list\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "layer_outputs = []\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    neuron_output = 0\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        neuron_output += n_input*weight\n",
    "    neuron_output+=neuron_bias\n",
    "    layer_outputs.append(neuron_output)\n",
    "print(f\"Layer Outputs: {layer_outputs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors, Arrays, and Vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are tensors?\n",
    "- tensors are a generalization of vectors and matrices\n",
    "- tensors are closely related to arrays\n",
    "- subtle differences between tensor/array/matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists\n",
    "- comma-separated values between square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple list\n",
    "l = [1,5,2,3]\n",
    "\n",
    "# list of lists\n",
    "lol = [[1,5,6,2],\n",
    "       [3,2,1,3]]\n",
    "\n",
    "# list of lists of lists\n",
    "lolol = [[[1,5,6,2],\n",
    "          [3,2,1,3],\n",
    "        [[5,2,1,2],\n",
    "         [6,4,8,4]],\n",
    "        [[2, 8,5,3],\n",
    "         [1, 1, 4,2]]]]\n",
    "\n",
    "# Everything could also be an array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cannot be an array because its not homologous\n",
    "# homologous if each list along a dimension is identically long\n",
    "\n",
    "another_list_of_lists = [[4,2,3],\n",
    "                         [5,1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix\n",
    "- rectangular array (columns and rows)\n",
    "- always 2-dimensional array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can all arrays be matrices?\n",
    "- No, not all arrays are matrices\n",
    "- matrices are always 2-dimensional\n",
    "- An array can be far more than just columns and rows\n",
    "- Arrays can have any number of dimensions (32 dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid matrix (bec/ has columns and rows)\n",
    "# automatically means it could also be an array\n",
    "\n",
    "list_matrix_array = [[4,2],\n",
    "                     [5,1],\n",
    "                     [8,2]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whats a Tensor?\n",
    "- A tensor object is an object that can be represented as an array\n",
    "\n",
    "What is an Array?\n",
    "- an ordered homologous container for numbers\n",
    "\n",
    "What is a Vector?\n",
    "- A list in python\n",
    "- 1-dimensional array in Numpy\n",
    "- unlike physics perspective where a vector is a quantity with magnitude and direction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product and Vector Addition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Multiplication\n",
    "- our previous python implementation of multiplying weight times input can be done using dot product\n",
    "- there are 2 ways of multiplying two vectors\n",
    "    - dot product\n",
    "    - cross product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot Product\n",
    "- dot product is a mathematical operation that takes two equal-length vectors and returns a single number, a scalar\n",
    "\n",
    "Dot Product Mulitplication\n",
    "- Equation: a * b = a1b1 + a2b2 + a3b3 + ... + anbn\n",
    "- both vectors have to be the same size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot product multiplication: 20\n"
     ]
    }
   ],
   "source": [
    "# Example of dot product multiplication\n",
    "\n",
    "a = [1, 2, 3] # think of this as neuron 1 inputs\n",
    "b = [2, 3, 4] # think of this as neuron 1 weights\n",
    "\n",
    "dot_product = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]\n",
    "print(f\"dot product multiplication: {dot_product}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Addition \n",
    "- to add two vectors, need to be performed element-wise (both vectors same size)\n",
    "- the result will be a vector of the same size as the input vectors\n",
    "- Equation: a + b = [a1 + b1, a2 + b2, a3 + b3, ... , an + bn]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Single Neuron with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Neuron Output: 4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# all for one neuron\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "# np.dot() does the dot product multiplication for us\n",
    "# whats going on: (0.2*1.0 + 0.8*2.0 + -0.5*3.0 + 1.0*2.5) + 2.0\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "print(f\"Single Neuron Output: {outputs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Layer of Neurons with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Outputs (3 Neurons): [4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "# weights for 3 different neurons\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "# biases for 3 different neurons\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "print(f\"Layer Outputs (3 Neurons): {layer_outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (4,)\n",
      "weights shape: (3, 4)\n",
      "Layer (without Bias): [ 2.8   -1.79   1.885]\n",
      "Layer (with Bias): [4.8   1.21  2.385]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "# weights for 3 different neurons\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "# biases for 3 different neurons\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "print(f\"inputs shape: {np.shape(inputs)}\")\n",
    "print(f\"weights shape: {np.shape(weights)}\")\n",
    "\n",
    "layer = np.dot(weights, inputs)\n",
    "layer_with_bias = np.dot(weights, inputs) + biases\n",
    "print(f\"Layer (without Bias): {layer}\") \n",
    "print(f\"Layer (with Bias): {layer_with_bias}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Batch of Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- when training we generally train on a batches of data (multiple inputs at a time)\n",
    "- 2 reasons why:\n",
    "    - 1. faster to train in batches in parallel processing\n",
    "    - 2. batches help generalize the model\n",
    "        - one sample at a time: if you fit the model to one sample at a time, the model will be biased towards that sample\n",
    "        - multiple samples at a time: the model will be able to produce general tweaks to the weights and biases as it sees multiple samples at a time (average of those)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](references/batches.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing Animation of why we use batches\n",
    "https://nnfs.io/vyu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example batch of data\n",
    "batch = [[1, 5, 2, 1],\n",
    "         [7, 3, 5, 2],\n",
    "         [1, 2, 3, 4],\n",
    "         [5, 6, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Product: an operation in which we take the dot product of each row of the first matrix with each column of the second matrix\n",
    "- the left matrix must match the size of the first dimension of the right matrix\n",
    "- Left Matrix: (5,4)\n",
    "- Right Matrix: (4,7) # 4 == 4\n",
    "- resulting matrix will be the size of the left matrix's first dimension and the right matrix's second dimension ---> (5,7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really good animation of how a matrix product is calculated: https://nnfs.io/jei/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](references/matrix_product.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposition for the Matrix Product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposition: modifies matrix so that the rows become columns and the columns become rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Layer of Neurons and Batch of Data w/ Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks from Scratch - P.4 Batches, Layers, and Objects (Video)\n",
    "https://www.youtube.com/watch?v=TEWy9vZcxW4&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3&t=91 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch size is amazing\n",
    "- we want a massive batch size because it will allow the model to generalize better\n",
    "- think of it as a human: you want as much inputs as possible to make a decision. you dont want to see one input at a time\n",
    "- the reason we dont want to just use the entire dataset is because it will just try to fit to all the data (i.e overfitting)\n",
    "- we want to use a batch size that is large enough to generalize the model but small enough to not overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# this is a single input with 4 features\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "output = np.dot(weights, inputs) + biases\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m weights \u001b[39m=\u001b[39m [[\u001b[39m0.2\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m, \u001b[39m1.0\u001b[39m],\n\u001b[1;32m      9\u001b[0m            [\u001b[39m0.5\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.91\u001b[39m, \u001b[39m0.26\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m],\n\u001b[1;32m     10\u001b[0m            [\u001b[39m-\u001b[39m\u001b[39m0.26\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.27\u001b[39m, \u001b[39m0.17\u001b[39m, \u001b[39m0.87\u001b[39m]]\n\u001b[1;32m     12\u001b[0m biases \u001b[39m=\u001b[39m [\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m0.5\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(weights, inputs) \u001b[39m+\u001b[39m biases\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOutput: \u001b[39m\u001b[39m{\u001b[39;00moutput\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# multiple inputs now\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "output = np.dot(weights, inputs) + biases\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# multiple inputs now\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "# reason we got an error in last cell is because shape error\n",
    "# the sizes of the arrays were not the same\n",
    "\n",
    "# size of index 1 of 1st array in np.dot needs to match size of index 0 of 2nd array\n",
    "# 4 != 3\n",
    "# what we need to do is TRANSPOSE the weights array bec/ we want to switch rows and columns\n",
    "output = np.dot(inputs, np.array(weights).T) + biases # switched inputs and weights around\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranpose:\n",
    "- transposing a matrix is flipping the rows and columns\n",
    "![image.png](references/transpose.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How matrix is calcualted:\n",
    "![image.png](references/matrix_product.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding another Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Outputs: \n",
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n",
      "Layer 2 Outputs: \n",
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "           [-0.5, 0.12, -0.33],\n",
    "           [-0.44, 0.73, -0.13]]\n",
    "\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases \n",
    "\n",
    "# the outputs of layer1 are the inputs of layer2\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "print(f\"Layer 1 Outputs: \\n{layer1_outputs}\")\n",
    "print(f\"Layer 2 Outputs: \\n{layer2_outputs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to convert this into an object so its not so unruly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we want small values when dealing with neural networks\n",
    "- we want to initialize the weights and biases to small values between -1 and +1\n",
    "- the reason we want it below 1 is because if say the first layer weights are 2 or 3 and the second layer weights are 4/5 then the output will be huge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights and Biases initialization:\n",
    "- weights good starting point is probably good to be -0.1 to 0.1\n",
    "- biases good starting point is probably good to be 0\n",
    "- biases starting at zero might create a problem where all the neurons are dead (i.e. all the neurons are outputting 0) if weights aren't high enough to fire (dead network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Output: \n",
      "[[ 0.10758131  1.03983522  0.24462411  0.31821498  0.18851053]\n",
      " [-0.08349796  0.70846411  0.00293357  0.44701525  0.36360538]\n",
      " [-0.50763245  0.55688422  0.07987797 -0.34889573  0.04553042]]\n",
      "Layer 2 Output: \n",
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X = [[1, 2, 3, 2.5],\n",
    "    [2.0, 5.0, -1.0, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # we don't need to transpose the weights array anymore\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons) # opposite order of n_inputs and n_neurons\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "## these are our layer objects\n",
    "# n_inputs is 4 because its the number of features in each input\n",
    "layer1 = Layer_Dense(n_inputs=4, n_neurons=5)\n",
    "# n_inputs is 5 because its the number of neurons in the previous layer\n",
    "# REMEMBER: size of index 1 of 1st array in np.dot needs to match size of index 0 of 2nd array\n",
    "layer2 = Layer_Dense(n_inputs=5, n_neurons=2)\n",
    "\n",
    "# we can now pass our inputs to the layer\n",
    "layer1.forward(inputs=X)\n",
    "print(f\"Layer 1 Output: \\n{layer1.output}\\n\")\n",
    "\n",
    "layer2.forward(inputs=layer1.output)\n",
    "print(f\"Layer 2 Output: \\n{layer2.output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next major step is to add activation functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Feb  3 2024, 15:58:27) \n[Clang 15.0.0 (clang-1500.3.9.4)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
